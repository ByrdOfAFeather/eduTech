{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Implementation Details\n",
    "The Rasch Model implementation in eduTech is based entirely on the implementation described in\n",
    "David Barber's book *\"Bayesian Reasoning and Machine Learning.\"* Barber describes the processes of estimating \n",
    "the model parameters in terms of Maximizing Likelihood, thus the current implementation in this package\n",
    "follows the same convention. The details of which are described below.\n",
    "\n",
    "Probability of a correct answer: \n",
    "\n",
    "$$p(X_{ij} = 1| s_i, q_j) = \\sigma(s_i - q_j)$$\n",
    "\n",
    "Loss Function:\n",
    "\n",
    "$$\\sum_{i,j} X_{ij}\\log(\\sigma(s_i-q_j) + (1-X_{ij})\\log(1-\\sigma(s_i-q_j))$$\n",
    "\n",
    "Derivative of loss in terms of student abilities:\n",
    "\n",
    "$$\\frac{\\partial{loss}}{\\partial{s_i}}  = \\sum_j X_{ij} - \\log(\\sigma(s_i-q_j) $$\n",
    "\n",
    "Derivative of loss in terms of question difficulties:\n",
    "\n",
    "$$\\frac{\\partial{loss}}{\\partial{q_j}}  = -\\sum_i X_{ij} - \\log(\\sigma(s_i-q_j) $$\n",
    "\n",
    "In practice these gradients are normalized by dividing by the gradient vector's mean as well as applying a learning rate to them."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Test Case\n",
    "The verification of eduTech's implementation comes from a matlab project that implements the\n",
    "same processes that Berber describes in his book.\n",
    "The repository can be found here: https://github.com/cosmicBboy/bayesian-reasoning-machine-learning. \n",
    "The testing data comes from a Penn state tutorial on item response theory (irt) which is the field of study \n",
    "that the Rasch model comes from. This data can be found here: https://quantdev.ssri.psu.edu/tutorials/introduction-irt-modeling.\n",
    "\n",
    "## 2.1 How to test for yourself\n",
    "First you are going to need to load the testing data into the matlab program. This is easily achieved by first converting the file \n",
    "into a .txt and then using matlab's importdata function.\n",
    "\n",
    "```\n",
    "testData = importData(\"ouirt.txt\")\n",
    "``` \n",
    "\n",
    "Secondly, you are going to need to transpose this dataset. This is simply how the matlab implementation expects it. \n",
    "```\n",
    "testData = transpose(testData); \n",
    "```\n",
    "\n",
    "Third, you are going to want to create three files named as below:\n",
    "* rasch.m\n",
    "* sigma.m\n",
    "* mynansum.m\n",
    "\n",
    "And copy and paste the following code snippets (taken from the repository mentioned above) into these files respectively:\n",
    "* rasch.m\n",
    "\n",
    "```\n",
    "function [a d ll]=rasch(X,opts)\n",
    "%rasch Fit a Rasch model to a binary matrix X\n",
    "% X contains binary data, coded 0 or 1 (nan if missing)\n",
    "% opts.eta_a - ability learning rate\n",
    "% opts.eta_d - difficulty learning rate\n",
    "% opts.plotprogress\n",
    "% opts.tol - log likelihood termination tolerance\n",
    "% see demoRasch.m\n",
    "\n",
    "% Maximum Likelood training using simple Gradient ascent:\n",
    "[Q S]=size(X);\n",
    "a=zeros(1,S); d=zeros(Q,1);\n",
    "\n",
    "if ~isfield(opts,'eta_a'); opts.eta_a=1; end % alpha learning rate\n",
    "if ~isfield(opts,'eta_d'); opts.eta_d=1; end % delta learning rate\n",
    "if ~isfield(opts,'plotprogress') opts.plotprogress=0; end % delta learning rate\n",
    "if ~isfield(opts,'tol') opts.tol=1e-6; end % termination toleration\n",
    "\n",
    "ll_old=-1e10;\n",
    "for loop=1:opts.maxits\n",
    "    sig = sigma(repmat(a,Q,1) - repmat(d,1,S));\n",
    "    loglik(loop) = mynansum(mynansum(X.*log(sig)+(1-X).*log(1-sig)));\n",
    "    \n",
    "    grada = mynansum(X-sig,1);\n",
    "    gradd = -mynansum(X-sig,2);\n",
    "    \n",
    "    a = a + opts.eta_a*grada/S;\n",
    "    d = d + opts.eta_d*gradd/Q;\n",
    "    if abs(loglik(end)-ll_old)<opts.tol; break; end; ll_old=loglik(end);\n",
    "    \n",
    "    if opts.plotprogress; plot(loglik); title('log likelihood'); drawnow; end\n",
    "end\n",
    "```\n",
    "\n",
    "* sigma.m\n",
    "\n",
    "```\n",
    "function s=sigma(x)\n",
    "%SIGMA 1./(1+exp(-x))\n",
    "% s=sigma(x) = 1./(1+exp(-x))\n",
    "s=1./(1+exp(-x));\n",
    "```\n",
    "\n",
    "* mynansum.m\n",
    "\n",
    "```\n",
    "function y = mynansum(x,d)\n",
    "%MYNANSUM sum of values that are not nan\n",
    "x(isnan(x))=0;\n",
    "if nargin==1; y = sum(x);\n",
    "else y = sum(x,d);\n",
    "end\n",
    "```\n",
    "\n",
    "\n",
    "Then to setup the options that correspond to this test run the following:\n",
    "\n",
    "```\n",
    "opts.maxits = 100\n",
    "opts.plotprogress = 1\n",
    "opts.eta_a = .01\n",
    "opts.eta_d = .01\n",
    "```\n",
    "\n",
    "Finally, run the following:\n",
    "\n",
    "```\n",
    "[student_abilities, question_difficulties] = rasch(testData, opts) \n",
    "```\n",
    "\n",
    "The following question difficulties should be obtained (student abilities has been omitted due to the overwhelming\n",
    "size): \n",
    "\n",
    "```\n",
    "1.7328\n",
    "1.0044\n",
    "0.7626\n",
    "0.8660\n",
    "0.2489\n",
    "0.7811\n",
    "0.3553\n",
    "0.6898\n",
    "0.7626\n",
    "2.5463\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "Now that we have the model's results in the matlab version, we compare to eduTech's implementation\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "LOSS AFTER 0 ITERATIONS: -3465.7294921875\nFinished fitting with a final loss of -2863.20263671875\n======= Student Abilities =======\n[[ 0.00975408]\n [-0.00022631]\n [ 0.00176978]\n [-0.00621456]\n [-0.00421847]\n [-0.00421847]\n [ 0.00176978]\n [-0.00222239]\n [-0.00222239]\n [-0.00222239]]\n.....\n======= Question Difficulties =======\n[[1.732794   1.0043824  0.7625858  0.8660217  0.24889438 0.7810914\n  0.35531518 0.6897581  0.7625858  2.5463223 ]]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# This will eventually change to edutech.irt but for now it's a relative import\n",
    "import pandas as pd \n",
    "from irt.rasch import RaschModel\n",
    "\n",
    "def load_test_data():\n",
    "    with open(\"ouirt.txt\", \"r\") as f:\n",
    "        rows = []\n",
    "        for line in f.readlines():\n",
    "            current_row = []\n",
    "            for no in line.split(\" \"):\n",
    "                try:\n",
    "                    current_row.append(int(no))\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            rows.append(current_row)\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "\n",
    "test_model = RaschModel(learning_rate=.01)\n",
    "test_data = load_test_data()\n",
    "test_model.fit(test_data, epochs=100)\n",
    "student_abilities, question_difficulties = test_model.get_model_descriptors()\n",
    "print(\"======= Student Abilities =======\")\n",
    "print(student_abilities[0:10])\n",
    "print(\".....\")\n",
    "print(\"======= Question Difficulties =======\")\n",
    "print(question_difficulties)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Results\n",
    "The same question difficulties are obtained, and through careful examination the same student abilities are obtained \n",
    "(with margin for error in rounding). This indicates that the Rasch model implemented in eduTech is reliable. For more information\n",
    "on why Maximum Likelihood was chosen as the optimizer as opposed to Marginal Maximum Likelihood or Bayesian Estimation  \n",
    "see the introduction notebook at the top of this module. \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}